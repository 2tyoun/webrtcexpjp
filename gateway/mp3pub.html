<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
  <title>Simple Pub</title>
  <style>
   .button {
       width: 150px;
       height: 50px;
   }
  </style>
</head>
<body>
 <h2>Publish to iOS</h2>
 <button class="button" onclick="startMedia()">StartMedia</button>
 <button class="button" onclick="stopMedia()">StopMedia</button>
 <br /><br />
 <button class="button" onclick="startPub()">Publish</button>
 <button class="button" onclick="stopPub()">Stop</button>

 <h3>Video</h3>
 <canvas id="snapshot_canvas" width="240px" height="180px" style="border: 1px solid blue;"></canvas>
 <video id="local_video" width="240px" height="180px" style="border: 1px solid black;"></video>
 <br />
 remoto image<br />
 <img id="remote_img" width="240px" height="180px" style="border: 1px solid red;"></img>

 <script>
  const BUFFER_SIZE =  4096 * 4; //1024;

  window.AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext;
  window.requestAnimationFrame = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame;
  window.cancelAnimationFrame = window.cancelAnimationFrame || window.webkitCancelAnimationFrame || window.mozCancelAnimationFrame;
  let audioContext = new window.AudioContext();
  let audio = {};
  audio.remoteGain = null;
  audio.source = null;
  audio.filter = null;
  audio.processor = null;
  audio.localGain = null;
  let _audioStartTime = 0;
  


  let localStream = null;
  let localVideo = document.getElementById('local_video');
  let snapshotCanvas = document.getElementById('snapshot_canvas');
  let snapshotContext = snapshotCanvas.getContext('2d');
  let remoteImage = document.getElementById('remote_img');
  let remoteAudioRange = document.getElementById('remote_volume');
  
  let timerId = null;
  let isConnected = false;

  let _worker = null;
  let _chName = '_simplepub_room';

  function connected() {
    return isConnected;
  }
  function setConnected(flag) {
    isConnected = flag;
  }


  function startMedia() {
    initWorker();

    navigator.mediaDevices.getUserMedia( {video:true, audio:true})
    .then((stream) => {
        localStream = stream;
        localVideo.srcObject = stream;
        localVideo.volume = 0;
        localVideo.play();

        startLocalAudio();
    })
    .catch((err) => 
        console.error('getUserMedia ERROR:', err)
    );
  }

  function initWorker() {
    if (_worker) {
      _worker.postMessage({
        type: 'INIT',
        server: 'http://localhost:3002/',
        room: '_ios_gateway_room',
        sampleRate: audioContext.sampleRate
      });
    }    
  }

  function stopMedia() {
    localVideo.stcObject = null;
    localStream.getTracks().forEach((track) =>
      track.stop()
    );
    localStream = null;
  }

  function startPub() {
    setConnected(true);
    timerId = setInterval(takeSnapshot, 2000);

    _readyAudio();
  }

  function stopPub() {
    setConnected(false);
    if (timerId) {
        clearInterval(timerId);
        timerId = null;
    }

    _resetAudio();
  }

  function takeSnapshot() {
      //console.log('snapshot..');
      snapshotContext.drawImage(localVideo, 
        0, 0, localVideo.videoWidth, localVideo.videoHeight,
        0, 0, snapshotCanvas.width, snapshotCanvas.height
      );

      if (! connected()) {
        return;
      }

      snapshotCanvas.toBlob(
          function(blob) {
                //_worker.postMessage({
                //  type: 'IMAGE',
                //  data: { buf: blob, ch: _chName }
                //});
                console.log('snapshot.. canvas.toBlob size=' + blob.size);
                if (_worker) {
                    _worker.postMessage({
                        type: 'IMAGE',
                        data: { blob: blob, ch: _chName }
                    });
                }
          },
          'image/jpeg'
      );
  }


// ---- message from worker ----
_worker = new Worker('mp3pub_worker.js');
_worker.addEventListener('message', _handleWorkerMsg);

  function _handleWorkerMsg(evt) {
    let payload = evt.data;
    switch (payload.type) {
      case 'notify':
        console.log('workerMsg: notify:' + payload.message);
        break;

      case 'ack':
      　//console.log('---- NOT USED----');
        console.log('workerMsg: ack:', payload.data);
        break;

      case 'image':
        _showRemoteImage(payload.data);
        break;

      case 'audio':
        //_handleAudioBuffer(payload.data);
        console.warn('AUDIO NOT HANDLED');
        break;

      case 'mp3_audio':
        _handleMp3Buffer(payload.data);
        //console.log('got mp3_audio byteLength=' + payload.data.byteLength);
        break;

      case 'data_url':
        _showRemoteDataUrl(payload.data);
        break;

      default:
        console.log('workerMsg: DEFAULT:', payload);
        break;
    }
  }

  // ---- for image ---
  function _showRemoteImage(buf) {
    //let len = buf.byteLength;
    //console.log('_showRemoteImage() IMAGE byteLength=' + len);

    if (remoteImage.src && (remoteImage.src != '')) {
      window.URL.revokeObjectURL(remoteImage.src);
      remoteImage.src = '';
    }

    //let blob = new Blob([buf], {type: 'image/png'});
    let blob = new Blob([buf], {type: 'image/jpeg'});
    remoteImage.src = window.URL.createObjectURL(blob);
  }

  function _clearImage() {
    remoteImage.removeAttribute('src');
  }

  function _showRemoteDataUrl(url) {
    console.log('_showRemoteDataUrl() data_url  len=' + url.length + '  url=' + url.slice(0, 50));
    remoteImage.src = url;
  }

  // --- for audio ---
  function startLocalAudio() {
    let ctx = audioContext;

    // マイク
    audio.source = ctx.createMediaStreamSource(localStream);

    // こちらを参考に（真似をする）
    //   https://github.com/leader22/audio-streaming-over-websocket
    //

    // 音質には期待しないのでモノラルで飛ばす
    audio.processor = ctx.createScriptProcessor(BUFFER_SIZE, 1, 1);
    audio.processor.onaudioprocess = _onAudioProcess;

    // 自分のフィードバックいらない
    audio.localGain = ctx.createGain();
    audio.localGain.gain.value = 0;
    audio.source.connect(audio.processor);

    audio.processor.connect(audio.localGain);
    audio.localGain.connect(ctx.destination);
  }

  function _onAudioProcess(evt) {
    let inputBuffer  = evt.inputBuffer;
    let outputBuffer = evt.outputBuffer;
    let inputData  = inputBuffer.getChannelData(0);
    //console.log('_onAudioProcess() inputData.length=' + inputData.length);

    // Bypassしつつ飛ばす
    //let outputData = outputBuffer.getChannelData(0);
    //outputData.set(inputData);

    if (! connected()) {
      return;
    }
    if (_worker) {
      _worker.postMessage({
        type: 'AUDIO',
        data: { buf: inputData, ch: _chName }
      });
    }
  }

  function _readyAudio() {
    audio.remoteGain = audioContext.createGain();
    audio.remoteGain.gain.value = 0;
    audio.remoteGain.connect(audioContext.destination);
  }

  function _resetAudio() {
    _disconnectAll(audio);
  }

  function _onChangeVolume() {
    let vol = remoteAudioRange.value;
    console.log('remoteAudioVolume=' + vol);
    if (audio.remoteGain) {
      audio.remoteGain.gain.value = vol / 100;
    }
  }


  function _disconnectAll(audioNodes) {
    Object.keys(audioNodes).forEach(function(key) {
      audioNodes[key] && audioNodes[key].disconnect();
      audioNodes[key] = null;
    });
  }

  function _handleAudioBuffer(buf) {
    let ctx = audioContext;
    let f32Audio = buf;
    if (! audio.remoteGain) {
      //console.warn('audioOutput not ready');
      return;
    }

    var audioBuffer = ctx.createBuffer(1, BUFFER_SIZE, ctx.sampleRate);
    audioBuffer.getChannelData(0).set(f32Audio);

    var source = ctx.createBufferSource();
    source.buffer = audioBuffer;
    //source.connect(audio.remoteGain);
    source.connect(audioContext.destination);

    var currentTime = ctx.currentTime;
    if (currentTime < _audioStartTime) {
      source.start(_audioStartTime);
      _audioStartTime += audioBuffer.duration;
    } else {
      source.start(_audioStartTime);
      _audioStartTime = currentTime + audioBuffer.duration;
    }
  }

  function _handleMp3Buffer(buf) {
    let ctx = audioContext;
    if (! audio.remoteGain) {
      return;
    }

    //let buf = data.buffer; // OK
    ctx.decodeAudioData(buf, function(audioBuffer) {
      console.log('mp3 decorderd. duration=' + audioBuffer.duration);
      let source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audio.remoteGain);

      let currentTime = ctx.currentTime;
      if (currentTime < _audioStartTime) {
        //source.start(audioPlaybackStartTime);
        source.start(0);
        _audioStartTime += audioBuffer.duration;
      }
      else if (currentTime > _audioStartTime + 1) {
        console.warn('playback too late, skip this buffer');
        source.disconnect();
        audioBuffer = null; 
        source = null;
        _audioStartTime = currentTime;
        return;
      }
      else {
        source.start(0);
        _audioStartTime = currentTime + audioBuffer.duration;
      }
    });
  }

 </script>
</body>
</html>
